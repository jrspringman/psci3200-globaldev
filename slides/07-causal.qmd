---
title: "Linear Regression"
subtitle: "Plus Survey Experiments and Autocratization"
author: "Jeremy Springman"
institute: "University of Pennsylvania"

format:
  revealjs:
    toc: false
    theme: [custom_iea.scss]
    width: 1050
    margin: 0.1
    logo: DevLab_Logo_29Mar2023.png
    footer: "jrspringman.github.io/psci3200-globaldev/"
    embed-resources: true
    template-partials:
    - title-slide.html
    gfm:
    mermaid-format: png
editor: source
---

# Logistics

## Assignments

- Today
  + DSS Ch 5
  + Create a git repo for this class (psci3200_yourname)
- Monday 
  + Migration readings (will post before Monday)
  + Git repo workshop (semi-optional)

## Agenda

1. Review Linear Regression
2. More Causal Inference
3. Directed Acyclical Graph workshop

# Linear Regression

## Linear Regression Model

\

$$
Y_i = \alpha + \beta X_i + \epsilon_i
$$


## Linear Regression Model

**Estimating model parameters**

$$
\hat{Y_i} = \hat{\alpha} + \hat{\beta} X_i
$$
**Coefficient**
$$
\hat{\beta} = \Delta{\hat{Y}} / \Delta{X}
$$


## Minimizing the Residuals

**What are residuals**

$$
\hat{\epsilon_i} = Y_i - \hat{Y_i}
$$

**How do we minimize them?**

$$
SSR = \sum_{i}^{N} \hat{\epsilon}_i^2
$$

##  {#slide3-id background-iframe="https://ellaudet.iq.harvard.edu/least_squares" background-interactive="true" data-menu-title="Visualization 1"}

## {#slide5-id background-iframe="https://ellaudet.iq.harvard.edu/linear_model" background-interactive="true" data-menu-title="Visualization 2"}

# Casaul Inference 3

## Identifying Assumptions

::: {.incremental}
- You must control for...
  + everything (observed and unobserved) that affects both the treatment variable and the outcome variable
- You *must not* control for...
  + anything that is affected by both the treatment variable and the outcome variable
::: 

## Confounding Variables

Affects both the probability of receiving the treatment and the value of the outcome
- We can't know what portion of the difference between treatment and control group can be attributed to the treatment vs something correlated with the probability of receiving the treatment

## Confounding Variables

```{r causal_coords}
#| echo: false
#| fig-width: 9

library(ggplot2)
library(ggdag)

causal_coords <- list(x = c(Treatment = 2, Outcome = 4, Confounder = 3),
                        y = c(Treatment = 2, Outcome = 2, Confounder = 4))  
  
confounder_dag = dagify(
  Outcome ~ Treatment + Confounder,
  Treatment ~ Confounder,
  exposure = "Treatment",
  outcome = "Outcome",
  latent = "Confounder",
  coords = causal_coords) 

confounder_dag |> 
  tidy_dagitty() |> 
  node_status() |> 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges() +
  geom_dag_point(aes(color = status), size = 14) +
  geom_dag_text(color = "black", size = 5) +
  scale_color_manual(values = c("#FF4136", "grey60", "#0074D9")) +
  guides(color = "none") +
  theme_dag()

```

## Confounding Variables

```{r causal_coords}
#| echo: false
#| fig-width: 9

library(ggplot2)
library(ggdag)

causal_coords <- list(x = c(Treatment = 2, Outcome = 4, Confounder = 3),
                        y = c(Treatment = 2, Outcome = 2, Confounder = 4))  
  
confounder_dag = dagify(
  Outcome ~ Treatment + Confounder,
  Treatment ~ Confounder,
  exposure = "Treatment",
  outcome = "Outcome",
  latent = "Confounder",
  coords = causal_coords) 

confounder_dag |> 
  tidy_dagitty() |> 
  node_status() |> 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges() +
  geom_dag_point(aes(color = status), size = 14) +
  geom_dag_text(color = "black", size = 5) +
  scale_color_manual(values = c("#FF4136", "grey60", "#0074D9")) +
  guides(color = "none") +
  theme_dag()

```

## Colliders

## Reverse Causality

- Timing

## Mechanisms

## Interactions

## Inference

Estimate = Estimand + Bias + Noise
Estimand: the true quantity of interest (e.g., the proportion of people who engage in bribery; the correlation between wealth and bribery)
Estimate: the number we get from our analysis. Our approximation to the true value. 
Estimator: the procedure we use to generate the estimate. 
Bias: errors that occur systematically
Noise: idiosyncratic (unsystematic) errors

## Identification strategy

Identification strategy: the way in which we use observational data to approximate an experiment (when treatment assignment is not random) and obtain an accurate and precise estimate of an effect. 
Experiments come next week.
It includes the assumptions we need to make to be able to interpret our estimates causally.

If we want to interpret a correlation as an unbiased (accurate and precise) estimate of a causal effect, we must believe that there are no baseline differences between treated and untreated units.
Identifying assumption: potential outcomes are independent of the treatment after controlling for the observed confounders.


## Holy Trinity of Causal Inference

1. Difference-in-Differences
2. Regression Discontinuity
3. Instrumental Variables

## Matching Approaches

- 
- Synthetic Control
